{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 01m 54s]\n",
      "f1_score: 0.8338509202003479\n",
      "\n",
      "Best f1_score So Far: 0.8362917900085449\n",
      "Total elapsed time: 00h 16m 17s\n",
      "Epoch 1/15\n",
      "5106/5121 [============================>.] - ETA: 0s - loss: 0.5376 - binary_accuracy: 0.7391 - precision_2: 0.7529 - recall_2: 0.9267 - f1_score: 0.8308"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Franco-SIM\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:2620: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  m.reset_state()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5121/5121 [==============================] - 11s 2ms/step - loss: 0.5375 - binary_accuracy: 0.7392 - precision_2: 0.7530 - recall_2: 0.9268 - f1_score: 0.8309 - val_loss: 0.5288 - val_binary_accuracy: 0.7395 - val_precision_2: 0.7364 - val_recall_2: 0.9702 - val_f1_score: 0.8373\n",
      "Epoch 2/15\n",
      "5121/5121 [==============================] - 10s 2ms/step - loss: 0.5281 - binary_accuracy: 0.7431 - precision_2: 0.7556 - recall_2: 0.9288 - f1_score: 0.8333 - val_loss: 0.5274 - val_binary_accuracy: 0.7410 - val_precision_2: 0.7442 - val_recall_2: 0.9527 - val_f1_score: 0.8356\n",
      "Epoch 3/15\n",
      "5121/5121 [==============================] - 9s 2ms/step - loss: 0.5254 - binary_accuracy: 0.7450 - precision_2: 0.7569 - recall_2: 0.9296 - f1_score: 0.8344 - val_loss: 0.5248 - val_binary_accuracy: 0.7448 - val_precision_2: 0.7568 - val_recall_2: 0.9292 - val_f1_score: 0.8342\n",
      "Epoch 4/15\n",
      "5121/5121 [==============================] - 9s 2ms/step - loss: 0.5236 - binary_accuracy: 0.7469 - precision_2: 0.7583 - recall_2: 0.9305 - f1_score: 0.8356 - val_loss: 0.5259 - val_binary_accuracy: 0.7443 - val_precision_2: 0.7458 - val_recall_2: 0.9556 - val_f1_score: 0.8378\n",
      "Epoch 5/15\n",
      "5121/5121 [==============================] - 10s 2ms/step - loss: 0.5224 - binary_accuracy: 0.7468 - precision_2: 0.7588 - recall_2: 0.9292 - f1_score: 0.8354 - val_loss: 0.5232 - val_binary_accuracy: 0.7474 - val_precision_2: 0.7777 - val_recall_2: 0.8883 - val_f1_score: 0.8293\n",
      "Epoch 6/15\n",
      "5121/5121 [==============================] - 10s 2ms/step - loss: 0.5220 - binary_accuracy: 0.7469 - precision_2: 0.7590 - recall_2: 0.9288 - f1_score: 0.8354 - val_loss: 0.5249 - val_binary_accuracy: 0.7465 - val_precision_2: 0.7577 - val_recall_2: 0.9306 - val_f1_score: 0.8353\n",
      "Epoch 7/15\n",
      "5121/5121 [==============================] - 9s 2ms/step - loss: 0.5213 - binary_accuracy: 0.7482 - precision_2: 0.7598 - recall_2: 0.9297 - f1_score: 0.8362 - val_loss: 0.5230 - val_binary_accuracy: 0.7455 - val_precision_2: 0.7606 - val_recall_2: 0.9216 - val_f1_score: 0.8334\n",
      "Epoch 8/15\n",
      "5121/5121 [==============================] - 9s 2ms/step - loss: 0.5204 - binary_accuracy: 0.7480 - precision_2: 0.7603 - recall_2: 0.9282 - f1_score: 0.8359 - val_loss: 0.5237 - val_binary_accuracy: 0.7464 - val_precision_2: 0.7552 - val_recall_2: 0.9365 - val_f1_score: 0.8361\n",
      "Epoch 9/15\n",
      "5121/5121 [==============================] - 9s 2ms/step - loss: 0.5206 - binary_accuracy: 0.7479 - precision_2: 0.7604 - recall_2: 0.9276 - f1_score: 0.8358 - val_loss: 0.5221 - val_binary_accuracy: 0.7440 - val_precision_2: 0.7562 - val_recall_2: 0.9291 - val_f1_score: 0.8338\n",
      "Epoch 10/15\n",
      "5121/5121 [==============================] - 9s 2ms/step - loss: 0.5193 - binary_accuracy: 0.7489 - precision_2: 0.7618 - recall_2: 0.9266 - f1_score: 0.8361 - val_loss: 0.5232 - val_binary_accuracy: 0.7469 - val_precision_2: 0.7542 - val_recall_2: 0.9402 - val_f1_score: 0.8370\n",
      "Epoch 11/15\n",
      "5121/5121 [==============================] - 10s 2ms/step - loss: 0.5190 - binary_accuracy: 0.7487 - precision_2: 0.7619 - recall_2: 0.9260 - f1_score: 0.8360 - val_loss: 0.5221 - val_binary_accuracy: 0.7460 - val_precision_2: 0.7476 - val_recall_2: 0.9546 - val_f1_score: 0.8385\n",
      "Epoch 12/15\n",
      "5121/5121 [==============================] - 10s 2ms/step - loss: 0.5188 - binary_accuracy: 0.7491 - precision_2: 0.7621 - recall_2: 0.9263 - f1_score: 0.8362 - val_loss: 0.5236 - val_binary_accuracy: 0.7469 - val_precision_2: 0.7561 - val_recall_2: 0.9353 - val_f1_score: 0.8362\n",
      "Epoch 13/15\n",
      "5121/5121 [==============================] - 9s 2ms/step - loss: 0.5177 - binary_accuracy: 0.7496 - precision_2: 0.7625 - recall_2: 0.9262 - f1_score: 0.8364 - val_loss: 0.5217 - val_binary_accuracy: 0.7451 - val_precision_2: 0.7431 - val_recall_2: 0.9647 - val_f1_score: 0.8395\n",
      "Epoch 14/15\n",
      "5121/5121 [==============================] - 9s 2ms/step - loss: 0.5179 - binary_accuracy: 0.7498 - precision_2: 0.7622 - recall_2: 0.9273 - f1_score: 0.8367 - val_loss: 0.5208 - val_binary_accuracy: 0.7464 - val_precision_2: 0.7713 - val_recall_2: 0.8998 - val_f1_score: 0.8306\n",
      "Epoch 15/15\n",
      "5121/5121 [==============================] - 10s 2ms/step - loss: 0.5175 - binary_accuracy: 0.7496 - precision_2: 0.7627 - recall_2: 0.9260 - f1_score: 0.8364 - val_loss: 0.5221 - val_binary_accuracy: 0.7463 - val_precision_2: 0.7720 - val_recall_2: 0.8980 - val_f1_score: 0.8303\n",
      "151/641 [======>.......................] - ETA: 0s - loss: 0.5252 - binary_accuracy: 0.7448 - precision_2: 0.7740 - recall_2: 0.8929 - f1_score: 0.8292"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Franco-SIM\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:2620: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  m.reset_state()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "641/641 [==============================] - 1s 1ms/step - loss: 0.5203 - binary_accuracy: 0.7516 - precision_2: 0.7765 - recall_2: 0.9009 - f1_score: 0.8341\n",
      "Test Evaluation: [0.5202629566192627, 0.7515988945960999, 0.7764756083488464, 0.900873601436615, 0.8340616822242737]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from kerastuner.tuners import RandomSearch, BayesianOptimization, Hyperband\n",
    "from kerastuner import Objective\n",
    "import joblib\n",
    "\n",
    "# Defino F1 Score metric\n",
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision = tf.keras.metrics.Precision()\n",
    "        self.recall = tf.keras.metrics.Recall()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.precision.update_state(y_true, y_pred)\n",
    "        self.recall.update_state(y_true, y_pred)\n",
    "\n",
    "    def result(self):\n",
    "        precision_result = self.precision.result()\n",
    "        recall_result = self.recall.result()\n",
    "        return 2 * (precision_result * recall_result) / (precision_result + recall_result + tf.keras.backend.epsilon())\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.precision.reset_states()\n",
    "        self.recall.reset_states()\n",
    "\n",
    "# Cargo el archivo CSV en un DataFrame\n",
    "df = pd.read_csv(\"datas.csv\")\n",
    "\n",
    "# Separo las características (X) y las etiquetas (y)\n",
    "X = df.drop(columns=[\"adopted\"])  # Todas las columnas excepto la columna \"adopted\"\n",
    "y = df[\"adopted\"]  # Columna \"adopted\" como etiqueta\n",
    "\n",
    "# Divido los datos en conjuntos de entrenamiento, validación y prueba\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Definir el keras tuner\n",
    "def build_model(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=(X_train.shape[1],)))\n",
    "    for i in range(hp.Int('num_layers', 2, 5)):\n",
    "        model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i), min_value=32, max_value=512, step=32),\n",
    "                                         activation='relu'))\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), F1Score()])  # Agrega las métricas\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define the tuners\n",
    "tuner_names = ['RandomSearch', 'BayesianOptimization']\n",
    "tuners = [RandomSearch, BayesianOptimization]\n",
    "\n",
    "# Perform the hyperparameter search with different tuners\n",
    "best_models = {}\n",
    "for tuner_name, tuner_class in zip(tuner_names, tuners):\n",
    "    print(f\"Performing {tuner_name} tuning:\")\n",
    "    tuner = tuner_class(\n",
    "        build_model,\n",
    "        objective=Objective(\"f1_score\", direction=\"max\"),\n",
    "        max_trials=5,\n",
    "        executions_per_trial=1,\n",
    "        directory=f'my_dir_{tuner_name.lower()}',\n",
    "        project_name='helloworld_6')\n",
    "\n",
    "    tuner.search(X_train, y_train,\n",
    "                 epochs=15,\n",
    "                 validation_data=(X_val, y_val))\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "    # Build the final model with the best hyperparameters\n",
    "    best_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "    # Train the final model\n",
    "    history = best_model.fit(X_train, y_train, epochs=15, validation_data=(X_val, y_val))\n",
    "\n",
    "    # Evaluate the final model\n",
    "    evaluation = best_model.evaluate(X_test, y_test)\n",
    "    print(\"Test Evaluation:\", evaluation)\n",
    "\n",
    "    # Get precision and F1 score from evaluation\n",
    "    precision = evaluation[2]  # Assuming precision is at index 2\n",
    "    f1 = evaluation[4]  # Assuming F1 score is at index 4\n",
    "\n",
    "    # Save the best model with precision and F1 score in the filename\n",
    "    model_name = f\"best_model_{tuner_name.lower()}_precision_{precision:.4f}_f1_{f1:.4f}.joblib\"\n",
    "    joblib.dump(best_model, model_name)\n",
    "\n",
    "    # Record the best model and evaluation\n",
    "    best_models[tuner_name] = {'model': best_model, 'evaluation': evaluation}\n",
    "\n",
    "# Write the results to a text file\n",
    "with open('tuning_results.txt', 'w') as f:\n",
    "    f.write(\"Tuning Results:\\n\")\n",
    "    for tuner_name, result in best_models.items():\n",
    "        f.write(f\"\\nTuner: {tuner_name}\\n\")\n",
    "        f.write(f\"Best Evaluation: {result['evaluation']}\\n\")\n",
    "        f.write(f\"Best Model: {result['model']}\\n\")\n",
    "        f.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
